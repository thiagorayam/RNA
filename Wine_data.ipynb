{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine_data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagorayam/RNA/blob/main/Wine_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snx0diGjiH6a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKoX1ziDVBq4"
      },
      "source": [
        "#kmeans\n",
        "\n",
        "def distance(x1, x2):\n",
        "    d=np.sqrt(np.sum(np.square(x1-x2)))\n",
        "    return d\n",
        "\n",
        "def clustering(X,centroids):\n",
        "    cluster_list = [[] for i in range(len(centroids))]\n",
        "    for x in X:\n",
        "      distances_list = []\n",
        "      for c in centroids:\n",
        "        distances_list.append(distance(c, x))\n",
        "      cluster_list[int(np.argmin(distances_list))].append(x)\n",
        "    return list((filter(None, cluster_list)))\n",
        "\n",
        "def get_centroids(cluster_list):\n",
        "    centroids = []\n",
        "    for j in range(len(cluster_list)):\n",
        "      centroids.append(np.mean(cluster_list[j], axis=0))\n",
        "    return centroids\n",
        "\n",
        "def kmeans(X,k,iter_max):\n",
        "\n",
        "  centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n",
        "\n",
        "  for _ in range(iter_max):\n",
        "\n",
        "    cluster_list = clustering(X,centroids)\n",
        "    next_centroids = get_centroids(cluster_list)\n",
        "    \n",
        "    if all(distance(next_centroids[i],centroids[i])==0 for i in range(len(centroids))):\n",
        "      return np.array(centroids), [np.std(x) for x in cluster_list]\n",
        "\n",
        "    centroids=next_centroids\n",
        "  return np.array(centroids), [np.std(x) for x in cluster_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFUApUmYmS2a"
      },
      "source": [
        "#RBF\n",
        "\n",
        "class RBF(object):\n",
        "\n",
        "    def __init__(self, max_iters=100):\n",
        "        self.max_iters=max_iters\n",
        "\n",
        "    def rbf(self, x, centroid, beta):\n",
        "        d = distance(x, centroid)\n",
        "        return np.exp((-beta)*d**2)\n",
        "\n",
        "    def rbf_list(self, X, centroids, beta_list):\n",
        "        RBF_list = []\n",
        "        for x in X:\n",
        "            RBF_line=[self.rbf(x, centroid, beta) for (centroid, beta) in zip(centroids, beta_list)]\n",
        "            RBF_line.append(1) #bias\n",
        "            RBF_list.append(RBF_line)\n",
        "        return np.array(RBF_list)\n",
        "  \n",
        "    def fit(self, X, y, k):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.k = k\n",
        "        self.centroids, self.std_list = kmeans(self.X, self.k, self.max_iters) \n",
        "        self.beta_list=1/(2*np.square(self.std_list))\n",
        "\n",
        "        RBF_X = self.rbf_list(self.X, self.centroids, self.beta_list)\n",
        "        self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.y\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        RBF_list = self.rbf_list(X, self.centroids, self.beta_list)\n",
        "        y=RBF_list @ self.w\n",
        "\n",
        "        for i in range (np.size(y, 0)):\n",
        "          index=np.argmax(y[i])\n",
        "          y[i,:]=0\n",
        "          y[i,index]=1\n",
        "\n",
        "        return y \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku-xrkVL1Q0M"
      },
      "source": [
        "#MLP\n",
        "\n",
        "class MLP(object):\n",
        "\n",
        "#Parâmetros da rede \n",
        "    def __init__(self, eta = 0.1, epoch =10000, epsilon=0.01, alfa=0):\n",
        "        self.eta = eta # taxa de aprendizagem\n",
        "        self.epoch = epoch # número máximo de épocas\n",
        "        self.epsilon = epsilon # erro médio admissível\n",
        "        self.alfa=alfa # fator do termo momentum\n",
        "        self.i=13 # número de neurônios na camada de entrada\n",
        "        self.j=3 # número de neurônios na camada escondida\n",
        "        self.k=3 # número de neurônios na camada de saída\n",
        "\n",
        "#Inicializa os pesos (matriz Wji) e bias (vetor teta_j) da rede. j,i representam os números de neurônios da camada de saída e entrada    \n",
        "    def inicialize(self): \n",
        "        self.w_ji=np.random.uniform(-1,1, [self.j,self.i+1])\n",
        "        self.w_kj=np.random.uniform(-1,1, [self.k,self.j+1])\n",
        "        return self\n",
        "\n",
        "#Função de ativação utilizada - sigmoide\n",
        "    def sigm(self, x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "#Derivada da função sigmoide\n",
        "    def d_sigm(self, x):\n",
        "        return x * (1.0 - x)\n",
        "\n",
        "#Cálculo da saída da camada escondida e da saída      \n",
        "    def feed_net(self, y_i):\n",
        "        self.y_i=y_i #entrada da camada i\n",
        "        self.y_j=self.sigm(np.dot(self.w_ji,np.concatenate((y_i,[1])))) #entrada da camada j, termo adicionado devido ao bias\n",
        "        self.y_k=self.sigm(np.dot(self.w_kj,np.concatenate((self.y_j,[1])))) #entrada da camada K, termo adicionado devido ao bias\n",
        "        return self\n",
        "\n",
        "#Cálculo da saída da camada escondida e da saída \n",
        "    def back_propagation(self, error):\n",
        "        delta_k=error*self.d_sigm(self.y_k) #Gradiente local do erro na camada de saída\n",
        "        delta_j=np.dot(self.w_kj.T,delta_k)*self.d_sigm(np.concatenate((self.y_j,[1]))) #Gradiente local do erro na camada escondida\n",
        "        delta_j=delta_j[0:self.j] # O último elemento representava apenas a relação do erro do bias, mas o bias não se interliga com a camada anterior.  \n",
        "        return delta_k,delta_j\n",
        "\n",
        "#Atualização dos pesos.\n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        emed=1.01\n",
        "        count=0 \n",
        "        self.inicialize()\n",
        "        deltaw_kj=0\n",
        "        deltaw_ji=0\n",
        "        \n",
        "        while (emed > self.epsilon and count < self.epoch):\n",
        "         \n",
        "         index = np.arange(X.shape[0])\n",
        "         np.random.shuffle(index)\n",
        "         X = X[index]\n",
        "         y = y[index]\n",
        "\n",
        "         emed=0\n",
        "         for n in range (np.size(X, 0)):\n",
        "\n",
        "           y_i=X[n,:]\n",
        "           self.feed_net(y_i)      \n",
        "           error=y[n,:]-self.y_k\n",
        "           emed += np.sum(np.square(error))\n",
        "           delta_k,delta_j=self.back_propagation(error) \n",
        "           self.w_kj=self.w_kj+self.eta*delta_k[:, np.newaxis]*np.concatenate((self.y_j,[1])) + self.alfa*deltaw_kj\n",
        "           self.w_ji=self.w_ji+self.eta*delta_j[:, np.newaxis]*np.concatenate((self.y_i,[1]))+ self.alfa*deltaw_ji\n",
        "           deltaw_kj=self.eta*delta_k[:, np.newaxis]*np.concatenate((self.y_j,[1])) + self.alfa*deltaw_kj\n",
        "           deltaw_ji=-self.eta*delta_j[:, np.newaxis]*np.concatenate((self.y_i,[1])) + self.alfa*deltaw_ji\n",
        "           self.feed_net(y_i)\n",
        "          \n",
        "         emed /= np.size(X, 0)\n",
        "         count += 1\n",
        "         print(emed)\n",
        "        print(count)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        ypred=[]\n",
        "        for n in range (np.size(X, 0)):\n",
        "          y_i=X[n,:]\n",
        "          self.feed_net(y_i)\n",
        "          ypred.append(self.y_k)\n",
        "        return np.around(np.array(ypred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve-hyVn7mDhv"
      },
      "source": [
        "#obtendo os dados\n",
        "\n",
        "N=178\n",
        "dim=13\n",
        "\n",
        "X=np.zeros((N, dim))\n",
        "y=np.zeros(N)\n",
        "ref_arquivo = open(\"/content/sample_data/wine.data\",\"r\")\n",
        "for j in range (N):\n",
        "  linha = ref_arquivo.readline()\n",
        "  valores=linha.split(',')\n",
        "  y[j]=valores[0]\n",
        "  for i in range(dim):\n",
        "    X[j,i]=valores[i+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj1KKmPz-3MN"
      },
      "source": [
        "#normalizando os dados\n",
        "X=X/X.max(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY9ytuQG9vGY"
      },
      "source": [
        "arr = np.zeros((len(y), 3))\n",
        "for i in range(len(y)):\n",
        "  c = int(y[i])-1\n",
        "  arr[i][c] = 1\n",
        "y=arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmZfVnfYmw8M"
      },
      "source": [
        "train_rate=0.75\n",
        "\n",
        "index = np.arange(X.shape[0])\n",
        "np.random.shuffle(index)\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "X_train=X[0:int(N*train_rate)]\n",
        "X_test=X[0:int(N*(1-train_rate))]\n",
        "y_train=y[0:int(N*train_rate)]\n",
        "y_test=y[0:int(N*(1-train_rate))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYUs5eHIoPnU"
      },
      "source": [
        "rbf = RBF()\n",
        "mlp = MLP(eta=0.2, epoch=500, epsilon=0.005, alfa=0.2)\n",
        "rbf.fit(X_train,y_train,3)\n",
        "mlp.fit(X_train,y_train)\n",
        "ypred_RBF=rbf.predict(X_test)\n",
        "ypred_MLP=mlp.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVmt2oxY8okc"
      },
      "source": [
        "error_mlp = (np.square(ypred_MLP-y_test)).sum(axis=1)\n",
        "error_rbf = (np.square(ypred_RBF-y_test)).sum(axis=1)\n",
        "ac_mlp = len(np.where(error_mlp == 0)[0])/len(error_mlp)\n",
        "ac_rbf = len(np.where(error_rbf == 0)[0])/len(error_rbf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3rqES-EP5Sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92abd626-3071-4efd-baaa-1d56a002bc58"
      },
      "source": [
        "print('Acurácia MLP : ', ac_mlp )\n",
        "print('Acurácia RBF : ', ac_rbf )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia MLP :  1.0\n",
            "Acurácia RBF :  0.8863636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}